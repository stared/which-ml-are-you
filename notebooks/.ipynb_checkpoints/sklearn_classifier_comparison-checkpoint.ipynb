{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh\n",
    "\n",
    "clf_names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=500),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twospirals(n_points, noise=.5):\n",
    "    \"\"\"\n",
    "     Returns the two spirals dataset.\n",
    "     https://glowingpython.blogspot.com/2017/04/solving-two-spirals-problem-with-keras.html\n",
    "    \"\"\"\n",
    "    n = np.sqrt(np.random.rand(n_points,1)) * 780 * (2*np.pi)/360\n",
    "    d1x = -np.cos(n)*n + np.random.rand(n_points,1) * noise\n",
    "    d1y = np.sin(n)*n + np.random.rand(n_points,1) * noise\n",
    "    return (np.vstack((np.hstack((d1x,d1y)),np.hstack((-d1x,-d1y)))), \n",
    "            np.hstack((np.zeros(n_points),np.ones(n_points))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(42)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.randn(100, 2)\n",
    "y = np.logical_xor(X[:, 0] > 0, X[:, 1] > 0)\n",
    "X += rng.uniform(size=X.shape)\n",
    "xor = (X, y)\n",
    "\n",
    "X, y = twospirals(100)\n",
    "X += 2 *rng.uniform(size=X.shape)\n",
    "spirals = (X, y)\n",
    "\n",
    "datasets = [make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable,\n",
    "            spirals,\n",
    "            xor\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure = plt.figure(figsize=(27, 9))\n",
    "# i = 1\n",
    "# # iterate over datasets\n",
    "# for ds_cnt, ds in enumerate(datasets):\n",
    "#     # preprocess dataset, split into training and test part\n",
    "#     X, y = ds\n",
    "#     X = StandardScaler().fit_transform(X)\n",
    "#     X_train, X_test, y_train, y_test = \\\n",
    "#         train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "#     x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "#     y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "#                          np.arange(y_min, y_max, h))\n",
    "\n",
    "#     # just plot the dataset first\n",
    "#     cm = plt.cm.RdBu\n",
    "#     cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "#     ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "#     if ds_cnt == 0:\n",
    "#         ax.set_title(\"Input data\")\n",
    "#     # Plot the training points\n",
    "#     ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "#                edgecolors='k')\n",
    "#     # Plot the testing points\n",
    "#     ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n",
    "#                edgecolors='k')\n",
    "#     ax.set_xlim(xx.min(), xx.max())\n",
    "#     ax.set_ylim(yy.min(), yy.max())\n",
    "#     ax.set_xticks(())\n",
    "#     ax.set_yticks(())\n",
    "#     i += 1\n",
    "\n",
    "#     # iterate over classifiers\n",
    "#     for name, clf in zip(names, classifiers):\n",
    "#         ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "#         clf.fit(X_train, y_train)\n",
    "#         score = clf.score(X_test, y_test)\n",
    "\n",
    "#         # Plot the decision boundary. For that, we will assign a color to each\n",
    "#         # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "#         if hasattr(clf, \"decision_function\"):\n",
    "#             Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "#         else:\n",
    "#             Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "#         # Put the result into a color plot\n",
    "#         Z = Z.reshape(xx.shape)\n",
    "#         ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "#         # Plot the training points\n",
    "#         ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "#                    edgecolors='k')\n",
    "#         # Plot the testing points\n",
    "#         ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "#                    edgecolors='k', alpha=0.6)\n",
    "\n",
    "#         ax.set_xlim(xx.min(), xx.max())\n",
    "#         ax.set_ylim(yy.min(), yy.max())\n",
    "#         ax.set_xticks(())\n",
    "#         ax.set_yticks(())\n",
    "#         if ds_cnt == 0:\n",
    "#             ax.set_title(name)\n",
    "#         ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "#                 size=15, horizontalalignment='right')\n",
    "#         i += 1\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# useful command to merge jsons:\n",
    "# jq -s '.' data*.json > all.json\n",
    "\n",
    "def get_dataset_dicts(X, y):\n",
    "    return [{'x': x1, 'y': x2, 'c': c}\n",
    "            for x1, x2, c in zip(X[:, 0].tolist(), X[:, 1].tolist(), y.tolist())]\n",
    "\n",
    "def save_dataset(X_train, X_test, y_train, y_test, name, kwargs):\n",
    "    with open('dataset-{}.json'.format(name), 'w') as f:\n",
    "        json.dump({\n",
    "            'name': name,\n",
    "            'data': {\n",
    "                'train': get_dataset_dicts(X_train, y_train),\n",
    "                'test': get_dataset_dicts(X_test, y_test),\n",
    "            },\n",
    "            **kwargs\n",
    "        },\n",
    "        f, indent=2)\n",
    "\n",
    "def save_prediction(ds_name, clf_name, X, y_pred, kwargs={}):\n",
    "    with open('prediction-{}-{}.json'.format(ds_name, clf_name), 'w') as f:\n",
    "        json.dump({\n",
    "            'clfname': clf_name,\n",
    "            'dsname': ds_name,\n",
    "            'data': get_dataset_dicts(X, y_pred.astype(int)),\n",
    "            **kwargs\n",
    "        },\n",
    "        f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(X):\n",
    "    # scale to [-1, 1]\n",
    "    for i in range(X.shape[1]):\n",
    "        X[:, i] = 2. * (X[:, i] - X[:, i].min()) / (X[:, i].max() - X[:, i].min()) - 1.\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds_names = ['moons', 'circles', 'linear', 'spirals', 'xor']\n",
    "\n",
    "Zs = []\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X = scale_dataset(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .2, X[:, 0].max() + .2\n",
    "    y_min, y_max = X[:, 1].min() - .2, X[:, 1].max() + .2\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "#                          np.arange(y_min, y_max, h))\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(-1, 1, 0.2),\n",
    "                     np.arange(-1, 1, 0.2))\n",
    "\n",
    "    \n",
    "    # save dataset\n",
    "    save_dataset(X_train, X_test, y_train, y_test, ds_names[ds_cnt],\n",
    "                {'xmin': x_min, 'xmax': x_max, 'ymin': y_min, 'ymax': y_max})\n",
    "    print({'xmin': x_min, 'xmax': x_max, 'ymin': y_min, 'ymax': y_max})\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "               edgecolors='k')\n",
    "    # Plot the testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n",
    "               edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    Zs.append({})\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(clf_names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "#         Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "        \n",
    "        save_prediction(ds_names[ds_cnt], name, np.c_[xx.ravel(), yy.ravel()], Z)\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        Zs[ds_cnt][name] = Z\n",
    "        \n",
    "        # Plot the training points\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "                   edgecolors='k')\n",
    "        # Plot the testing points\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "                   edgecolors='k', alpha=0.6)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name)\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                size=15, horizontalalignment='right')\n",
    "        i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(pred1, pred2):\n",
    "    return np.sum(pred1 == pred2) / (pred1.shape[0] * pred2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "preds = Zs[0]\n",
    "comparisons = pd.Series()\n",
    "for clf1, clf2 in itertools.combinations(preds.keys(), 2):\n",
    "    comparisons['{} vs {}'.format(clf1, clf2)] = compare(preds[clf1], preds[clf2])\n",
    "\n",
    "comparisons.sort_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
